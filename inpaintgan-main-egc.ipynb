{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "class Config(dict):\n",
    "    def __init__(self):\n",
    "        self._dict = dict()\n",
    "        self._dict['PATH'] = os.path.dirname('/kaggle/working/')\n",
    "    def __getattr__(self, name):\n",
    "        if self._dict.get(name) is not None:\n",
    "            return self._dict[name]\n",
    "        if DEFAULT_CONFIG.get(name) is not None:\n",
    "            return DEFAULT_CONFIG[name]\n",
    "        return None\n",
    "\n",
    "\n",
    "DEFAULT_CONFIG = {\n",
    "    'MODE': 1,                      # 1: train, 2: test, 3: eval\n",
    "    'MODEL': 4,                     # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
    "    'MASK': 1,                      # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
    "    'EDGE': 1,                      # 1: canny, 2: external\n",
    "    'NMS': 1,                       # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
    "    'SEED': 10,                     # random seed\n",
    "    'GPU': [0],                     # list of gpu ids\n",
    "    'DEBUG': 0,                     # turns on debugging mode\n",
    "    'VERBOSE': 2,                   # turns on verbose mode in the output console\n",
    "\n",
    "    'LR': 0.0001,                    # learning rate\n",
    "    'D2G_LR': 0.1,                  # discriminator/generator learning rate ratio\n",
    "    'BETA1': 0.01,                   # adam optimizer beta1\n",
    "    'BETA2': 0.9,                   # adam optimizer beta2\n",
    "    'BATCH_SIZE': 8,                # input batch size for training\n",
    "    'INPUT_SIZE': 256,              # input image size for training 0 for original size\n",
    "    'SIGMA': 1.9,                   # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
    "    'MAX_ITERS': 2e6,               # maximum number of iterations to train the model\n",
    "\n",
    "    'EDGE_THRESHOLD': 0.5,          # edge detection threshold\n",
    "    'L1_LOSS_WEIGHT': 1,            # l1 loss weight\n",
    "    'FM_LOSS_WEIGHT': 10,           # feature-matching loss weight\n",
    "    'STYLE_LOSS_WEIGHT': 250,         # style loss weight\n",
    "    'CONTENT_LOSS_WEIGHT': 0.1,       # perceptual loss weight\n",
    "    'INPAINT_ADV_LOSS_WEIGHT': 0.1,# adversarial loss weight\n",
    "\n",
    "    'GAN_LOSS': 'nsgan',            # nsgan | lsgan | hinge\n",
    "    'GAN_POOL_SIZE': 0,             # fake images pool size\n",
    "\n",
    "    'SAVE_INTERVAL': 1000,          # how many iterations to wait before saving model (0: never)\n",
    "    'SAMPLE_INTERVAL': 1000,        # how many iterations to wait before sampling (0: never)\n",
    "    'SAMPLE_SIZE': 12,              # number of images to sample\n",
    "    'EVAL_INTERVAL': 0,             # how many iterations to wait before model evaluation (0: never)\n",
    "    'LOG_INTERVAL': 10,             # how many iterations to wait before logging training status (0: never)\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.381214Z",
     "iopub.execute_input": "2023-05-18T14:34:23.382008Z",
     "iopub.status.idle": "2023-05-18T14:34:23.396371Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.381963Z",
     "shell.execute_reply": "2023-05-18T14:34:23.395380Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import scipy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import canny\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,input_size, filepath, augment=True, training=True, isVal=False, facesDataSet=False):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.augment = augment\n",
    "        self.training = training\n",
    "        self.isVal = isVal\n",
    "        if facesDataSet == False:\n",
    "            if isVal == False:\n",
    "                with open('/kaggle/input/file-list/places365_train_standard.txt', 'r') as f:\n",
    "                    self.imageNames = [line.split(None, 1)[0] for line in f]\n",
    "                    self.imageNames = self.imageNames[:5000]\n",
    "                    print(len(self.imageNames))\n",
    "            else:\n",
    "                 with open('/kaggle/input/file-list/places365_val.txt', 'r') as f:\n",
    "                    self.imageNames = [line.split(None, 1)[0] for line in f]\n",
    "        self.facesDataSet = facesDataSet\n",
    "        self.data = self.load_flist(filepath)\n",
    "        self.input_size = input_size\n",
    "#             self.edge_data = self.load_flist(edge_flist)\n",
    "#             self.mask_data = self.load_flist(mask_flist)\n",
    "\n",
    "        self.nms = config.NMS\n",
    "        self.sigma = config.SIGMA\n",
    "        self.edge = config.EDGE\n",
    "        self.mask = config.MASK\n",
    "\n",
    "        # in test mode, there's a one-to-one relationship between mask and image\n",
    "        # masks are loaded non random\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            item = self.load_item(index)\n",
    "        except:\n",
    "            print('loading error: ' + self.data[index])\n",
    "            item = self.load_item(0)\n",
    "\n",
    "        return item\n",
    "\n",
    "    def load_flist(self, flist):\n",
    "        imagesPath = []\n",
    "        if self.facesDataSet:\n",
    "            if os.path.isdir(flist):\n",
    "                return list(glob.glob(flist + '/*.jpg')) + list(glob.glob(flist + '/*.png')) + list(glob.glob(flist + '/*.jpeg'))\n",
    "        for filename in self.imageNames:\n",
    "            if self.isVal == False:\n",
    "                imagesPath.append(os.path.join(flist,filename[1:]))\n",
    "            else:\n",
    "                imagesPath.append(os.path.join(flist,filename))\n",
    "            \n",
    "#         To run on subset of images:\n",
    "#         if self.isVal == False:\n",
    "#             imagesPath = imagesPath[304896:]\n",
    "        return imagesPath\n",
    "    def load_name(self, index):\n",
    "        name = self.data[index]\n",
    "        return os.path.basename(name)\n",
    "    \n",
    "    def load_item(self, index):\n",
    "        size = self.input_size\n",
    "        img =  cv2.imread(self.data[index])\n",
    "        if len(img.shape) < 3:\n",
    "            img = gray2rgb(img)\n",
    "        if size != 0:\n",
    "            img = self.resize(img, size, size)\n",
    "        img_gray = rgb2gray(img)\n",
    "        mask = self.load_mask(img, index)\n",
    "        edge = self.load_edge(img_gray, index, mask)\n",
    "        if self.augment and np.random.binomial(1, 0.5) > 0:\n",
    "            img = img[:, ::-1, ...]\n",
    "            img_gray = img_gray[:, ::-1, ...]\n",
    "            edge = edge[:, ::-1, ...]\n",
    "            mask = mask[:, ::-1, ...]\n",
    "\n",
    "        return self.to_tensor(img), self.to_tensor(img_gray), self.to_tensor(edge), self.to_tensor(mask)\n",
    "    \n",
    "    def load_edge(self, img, index, mask):\n",
    "        sigma = self.sigma\n",
    "        mask = None if self.training else (1 - mask / 255).astype(np.bool)\n",
    "\n",
    "        # canny\n",
    "        # no edge\n",
    "        if sigma == -1:\n",
    "            return np.zeros(img.shape).astype(np.float)\n",
    "\n",
    "        # random sigma\n",
    "        if sigma == 0:\n",
    "            sigma = random.randint(1, 4)\n",
    "\n",
    "        return canny(img, sigma=sigma, mask=mask).astype(np.float)\n",
    "    \n",
    "    def load_mask(self, img, index):\n",
    "        imgh, imgw = img.shape[0:2]\n",
    "        mask_type = self.mask\n",
    "\n",
    "        # external + random block\n",
    "        if mask_type == 4:\n",
    "            mask_type = 1 if np.random.binomial(1, 0.5) == 1 else 3\n",
    "\n",
    "        # external + random block + half\n",
    "        elif mask_type == 5:\n",
    "            mask_type = np.random.randint(1, 4)\n",
    "\n",
    "        # random block\n",
    "        if mask_type == 1:\n",
    "            return self.create_mask(imgw, imgh, imgw // 8, imgh // 8)\n",
    "\n",
    "        # half\n",
    "        if mask_type == 2:\n",
    "            # randomly choose right or left\n",
    "            return self.create_mask(imgw, imgh, imgw // 2, imgh, 0 if random.random() < 0.5 else imgw // 2, 0)\n",
    "\n",
    "        # external\n",
    "        if mask_type == 3:\n",
    "            mask_index = random.randint(0, len(self.mask_data) - 1)\n",
    "            mask = cv2.imread(self.mask_data[mask_index])\n",
    "            mask = self.resize(mask, imgh, imgw)\n",
    "            mask = (mask > 0).astype(np.uint8) * 255       # threshold due to interpolation\n",
    "            return mask\n",
    "\n",
    "        # test mode: load mask non random\n",
    "        if mask_type == 6:\n",
    "            mask = cv2.imread(self.mask_data[index])\n",
    "            mask = self.resize(mask, imgh, imgw, centerCrop=False)\n",
    "            mask = rgb2gray(mask)\n",
    "            mask = (mask > 0).astype(np.uint8) * 255\n",
    "            return mask\n",
    "        \n",
    "    def resize(self, img, height, width, centerCrop=True):\n",
    "        imgh, imgw = img.shape[0:2]\n",
    "        if centerCrop and imgh != imgw:\n",
    "            # center crop\n",
    "            side = np.minimum(imgh, imgw)\n",
    "            j = (imgh - side) // 2\n",
    "            i = (imgw - side) // 2\n",
    "            img = img[j:j + side, i:i + side, ...]\n",
    "\n",
    "        img = cv2.resize(img, (height, width))\n",
    "        return img  \n",
    "    \n",
    "    def to_tensor(self, img):\n",
    "        img = Image.fromarray(img)\n",
    "#         plt.imshow(img)    \n",
    "#         plt.show()\n",
    "        img_t = F.to_tensor(img).float()\n",
    "        return img_t\n",
    "    \n",
    "    def create_mask(self, width, height, mask_width, mask_height, x=None, y=None):\n",
    "        mask = np.zeros((height, width))\n",
    "        mask_x = x if x is not None else random.randint(0, width - mask_width)\n",
    "        mask_y = y if y is not None else random.randint(0, height - mask_height)\n",
    "        mask[mask_y:mask_y + mask_height, mask_x:mask_x + mask_width] = 1\n",
    "        return mask\n",
    "    def create_iterator(self, batch_size):\n",
    "        while True:\n",
    "            sample_loader = DataLoader(\n",
    "                dataset=self,\n",
    "                batch_size=batch_size,\n",
    "                drop_last=True\n",
    "            )\n",
    "\n",
    "            for item in sample_loader:\n",
    "                yield item"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.639761Z",
     "iopub.execute_input": "2023-05-18T14:34:23.641150Z",
     "iopub.status.idle": "2023-05-18T14:34:23.687490Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.641103Z",
     "shell.execute_reply": "2023-05-18T14:34:23.686323Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BaseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNetwork, self).__init__()\n",
    "\n",
    "    def init_weights(self, init_type='normal', gain=0.02):\n",
    "        '''\n",
    "        initialize network's weights\n",
    "        init_type: normal | xavier | kaiming | orthogonal\n",
    "        https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n",
    "        '''\n",
    "\n",
    "        def init_func(m):\n",
    "            classname = m.__class__.__name__\n",
    "            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "                if init_type == 'normal':\n",
    "                    nn.init.normal_(m.weight.data, 0.0, gain)\n",
    "                elif init_type == 'xavier':\n",
    "                    nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "                elif init_type == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "                elif init_type == 'orthogonal':\n",
    "                    nn.init.orthogonal_(m.weight.data, gain=gain)\n",
    "\n",
    "                if hasattr(m, 'bias') and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "            elif classname.find('BatchNorm2d') != -1:\n",
    "                nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "        self.apply(init_func)\n",
    "\n",
    "class InpaintGenerator(BaseNetwork):\n",
    "    def __init__(self, residual_blocks=8, init_weights=True):\n",
    "        super(InpaintGenerator, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels=4, out_channels=64, kernel_size=7, padding=0),\n",
    "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        blocks = []\n",
    "        for _ in range(residual_blocks):\n",
    "            block = ResnetBlock(256, 2)\n",
    "            blocks.append(block)\n",
    "\n",
    "        self.middle = nn.Sequential(*blocks)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=7, padding=0),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        x = (torch.tanh(x) + 1) / 2\n",
    "        return x\n",
    "\n",
    "\n",
    "class Ginput(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 32, kernel_size = 3, stride = 2, padding = 1):\n",
    "        super(Ginput, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.mask_conv = nn.Conv2d(1, 1, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, edge, mask):\n",
    "        \n",
    "        G0 = self.conv(torch.cat([edge,mask], dim=1))\n",
    "        mask = self.mask_conv(mask)\n",
    "        F0 = torch.sigmoid(G0)\n",
    "        return F0, G0, mask\n",
    "\n",
    "class EGC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(EGC, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, 1, padding)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.mask_conv = nn.Conv2d(1, 1, kernel_size, stride, padding)\n",
    "        self.gate_conv = nn.Conv2d(in_channels+out_channels+1, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, F_prev, G_prev, mask):\n",
    "        F = torch.sigmoid(self.conv1(F_prev))\n",
    "        G = self.gate_conv((torch.cat([F, G_prev, mask], dim=1)))\n",
    "        mask = self.mask_conv(mask)\n",
    "        F = torch.relu(self.conv2(F_prev)) * torch.sigmoid(G)\n",
    "        return F, G, mask\n",
    "\n",
    "class ShallowFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowFeatures, self).__init__()\n",
    "        self.Ginput = Ginput()\n",
    "        self.EGC_layer_2 = EGC(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.EGC_layer_3 = EGC(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.EGC_layer_4 = EGC(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.EGC_layer_5 = EGC(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.EGC_layer_6 = EGC(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, edge, mask):\n",
    "        F, G, mask = self.Ginput(edge, mask)      \n",
    "        F, G, mask = self.EGC_layer_2(F, G, mask)\n",
    "        F, G, mask = self.EGC_layer_3(F, G, mask)\n",
    "        F, G, mask = self.EGC_layer_4(F, G, mask)\n",
    "        F, G, mask = self.EGC_layer_5(F, G, mask)\n",
    "        F, G, mask = self.EGC_layer_6(F, G, mask)\n",
    "        return F\n",
    "\n",
    "class EdgeGenerator(BaseNetwork):\n",
    "    def __init__(self, residual_blocks=8, use_spectral_norm=True, init_weights=True):\n",
    "        super(EdgeGenerator, self).__init__()\n",
    "        \n",
    "        self.encoder = ShallowFeatures()\n",
    "        \n",
    "        blocks = []\n",
    "        for _ in range(residual_blocks):\n",
    "            block = ResnetBlock(256, 2, use_spectral_norm=use_spectral_norm)\n",
    "            blocks.append(block)\n",
    "\n",
    "        self.middle = nn.Sequential(*blocks)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            spectral_norm(nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(256, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            spectral_norm(nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(256, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            spectral_norm(nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            spectral_norm(nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            spectral_norm(nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7, padding=0),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "\n",
    "    def forward(self, edge, mask):\n",
    "        x = self.encoder(edge, mask)\n",
    "        x1 = self.middle(x)\n",
    "        x1 = torch.cat([x,x1], dim=1)\n",
    "        x1 = self.decoder(x1)\n",
    "        x1 = torch.sigmoid(x1)\n",
    "        return x1\n",
    "\n",
    "\n",
    "class Discriminator(BaseNetwork):\n",
    "    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True, init_weights=True):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "        self.conv1 = self.features = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        outputs = conv5\n",
    "        if self.use_sigmoid:\n",
    "            outputs = torch.sigmoid(conv5)\n",
    "\n",
    "        return outputs, [conv1, conv2, conv3, conv4, conv5]\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dilation=1, use_spectral_norm=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(dilation),\n",
    "            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=dilation, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(dim, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(dim, track_running_stats=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "\n",
    "        # Remove ReLU at the end of the residual block\n",
    "        # http://torch.ch/blog/2016/02/04/resnets.html\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def spectral_norm(module, mode=True):\n",
    "    if mode:\n",
    "        return nn.utils.spectral_norm(module)\n",
    "\n",
    "    return module"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.690835Z",
     "iopub.execute_input": "2023-05-18T14:34:23.691767Z",
     "iopub.status.idle": "2023-05-18T14:34:23.755882Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.691727Z",
     "shell.execute_reply": "2023-05-18T14:34:23.754799Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class AdversarialLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "    Adversarial loss\n",
    "    https://arxiv.org/abs/1711.10337\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, type='nsgan', target_real_label=1.0, target_fake_label=0.0):\n",
    "        r\"\"\"\n",
    "        type = nsgan | lsgan | hinge\n",
    "        \"\"\"\n",
    "        super(AdversarialLoss, self).__init__()\n",
    "\n",
    "        self.type = type\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "\n",
    "        if type == 'nsgan':\n",
    "            self.criterion = nn.BCELoss()\n",
    "\n",
    "        elif type == 'lsgan':\n",
    "            self.criterion = nn.MSELoss()\n",
    "\n",
    "        elif type == 'hinge':\n",
    "            self.criterion = nn.ReLU()\n",
    "\n",
    "    def __call__(self, outputs, is_real, is_disc=None):\n",
    "        if self.type == 'hinge':\n",
    "            if is_disc:\n",
    "                if is_real:\n",
    "                    outputs = -outputs\n",
    "                return self.criterion(1 + outputs).mean()\n",
    "            else:\n",
    "                return (-outputs).mean()\n",
    "\n",
    "        else:\n",
    "            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            return loss\n",
    "\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "    Perceptual loss, VGG-based\n",
    "    https://arxiv.org/abs/1603.08155\n",
    "    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.add_module('vgg', VGG19())\n",
    "        self.criterion = torch.nn.L1Loss()\n",
    "\n",
    "    def compute_gram(self, x):\n",
    "        b, ch, h, w = x.size()\n",
    "        f = x.view(b, ch, w * h)\n",
    "        f_T = f.transpose(1, 2)\n",
    "        G = f.bmm(f_T) / (h * w * ch)\n",
    "\n",
    "        return G\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        # Compute features\n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "\n",
    "        # Compute loss\n",
    "        style_loss = 0.0\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu2_2']), self.compute_gram(y_vgg['relu2_2']))\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu3_4']), self.compute_gram(y_vgg['relu3_4']))\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu4_4']), self.compute_gram(y_vgg['relu4_4']))\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu5_2']), self.compute_gram(y_vgg['relu5_2']))\n",
    "\n",
    "        return style_loss\n",
    "\n",
    "\n",
    "\n",
    "class PerceptualLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "    Perceptual loss, VGG-based\n",
    "    https://arxiv.org/abs/1603.08155\n",
    "    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        self.add_module('vgg', VGG19())\n",
    "        self.criterion = torch.nn.L1Loss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        # Compute features\n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "\n",
    "        content_loss = 0.0\n",
    "        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n",
    "        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n",
    "        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n",
    "        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n",
    "        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n",
    "\n",
    "\n",
    "        return content_loss\n",
    "\n",
    "\n",
    "\n",
    "class VGG19(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19, self).__init__()\n",
    "        features = models.vgg19(pretrained=True).features\n",
    "        self.relu1_1 = torch.nn.Sequential()\n",
    "        self.relu1_2 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu2_1 = torch.nn.Sequential()\n",
    "        self.relu2_2 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu3_1 = torch.nn.Sequential()\n",
    "        self.relu3_2 = torch.nn.Sequential()\n",
    "        self.relu3_3 = torch.nn.Sequential()\n",
    "        self.relu3_4 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu4_1 = torch.nn.Sequential()\n",
    "        self.relu4_2 = torch.nn.Sequential()\n",
    "        self.relu4_3 = torch.nn.Sequential()\n",
    "        self.relu4_4 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu5_1 = torch.nn.Sequential()\n",
    "        self.relu5_2 = torch.nn.Sequential()\n",
    "        self.relu5_3 = torch.nn.Sequential()\n",
    "        self.relu5_4 = torch.nn.Sequential()\n",
    "\n",
    "        for x in range(2):\n",
    "            self.relu1_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(2, 4):\n",
    "            self.relu1_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(4, 7):\n",
    "            self.relu2_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(7, 9):\n",
    "            self.relu2_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(9, 12):\n",
    "            self.relu3_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(12, 14):\n",
    "            self.relu3_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(14, 16):\n",
    "            self.relu3_3.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(16, 18):\n",
    "            self.relu3_4.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(18, 21):\n",
    "            self.relu4_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(21, 23):\n",
    "            self.relu4_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(23, 25):\n",
    "            self.relu4_3.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(25, 27):\n",
    "            self.relu4_4.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(27, 30):\n",
    "            self.relu5_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(30, 32):\n",
    "            self.relu5_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(32, 34):\n",
    "            self.relu5_3.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(34, 36):\n",
    "            self.relu5_4.add_module(str(x), features[x])\n",
    "\n",
    "        # don't need the gradients, just want the features\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        relu1_1 = self.relu1_1(x)\n",
    "        relu1_2 = self.relu1_2(relu1_1)\n",
    "\n",
    "        relu2_1 = self.relu2_1(relu1_2)\n",
    "        relu2_2 = self.relu2_2(relu2_1)\n",
    "\n",
    "        relu3_1 = self.relu3_1(relu2_2)\n",
    "        relu3_2 = self.relu3_2(relu3_1)\n",
    "        relu3_3 = self.relu3_3(relu3_2)\n",
    "        relu3_4 = self.relu3_4(relu3_3)\n",
    "\n",
    "        relu4_1 = self.relu4_1(relu3_4)\n",
    "        relu4_2 = self.relu4_2(relu4_1)\n",
    "        relu4_3 = self.relu4_3(relu4_2)\n",
    "        relu4_4 = self.relu4_4(relu4_3)\n",
    "\n",
    "        relu5_1 = self.relu5_1(relu4_4)\n",
    "        relu5_2 = self.relu5_2(relu5_1)\n",
    "        relu5_3 = self.relu5_3(relu5_2)\n",
    "        relu5_4 = self.relu5_4(relu5_3)\n",
    "\n",
    "        out = {\n",
    "            'relu1_1': relu1_1,\n",
    "            'relu1_2': relu1_2,\n",
    "\n",
    "            'relu2_1': relu2_1,\n",
    "            'relu2_2': relu2_2,\n",
    "\n",
    "            'relu3_1': relu3_1,\n",
    "            'relu3_2': relu3_2,\n",
    "            'relu3_3': relu3_3,\n",
    "            'relu3_4': relu3_4,\n",
    "\n",
    "            'relu4_1': relu4_1,\n",
    "            'relu4_2': relu4_2,\n",
    "            'relu4_3': relu4_3,\n",
    "            'relu4_4': relu4_4,\n",
    "\n",
    "            'relu5_1': relu5_1,\n",
    "            'relu5_2': relu5_2,\n",
    "            'relu5_3': relu5_3,\n",
    "            'relu5_4': relu5_4,\n",
    "        }\n",
    "        return out"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.757625Z",
     "iopub.execute_input": "2023-05-18T14:34:23.759156Z",
     "iopub.status.idle": "2023-05-18T14:34:23.805685Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.759125Z",
     "shell.execute_reply": "2023-05-18T14:34:23.804646Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, name, config):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.iteration = 0\n",
    "\n",
    "#         print(config.PATH)\n",
    "        \n",
    "        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n",
    "        self.gen_adam_path = os.path.join(config.PATH, name + '_optimizer_' + '_gen.pth')\n",
    "        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n",
    "        self.dis_adam_path = os.path.join(config.PATH, name + '_optimizer_' + '_dis.pth')\n",
    "\n",
    "    def load(self):\n",
    "        print('in load', self.name, self.gen_weights_path)\n",
    "        gen_weights_path = '/kaggle/input/weights/' + self.name + '_gen.pth'\n",
    "        dis_weights_path = '/kaggle/input/weights/' + self.name + '_dis.pth'\n",
    "        \n",
    "        gen_adam_path = '/kaggle/input/weights/' + self.name + '_optimizer_' + '_gen.pth'\n",
    "        dis_adam_path = '/kaggle/input/weights/' + self.name + '_optimizer_' + '_dis.pth'\n",
    "        \n",
    "        if os.path.exists(gen_weights_path):\n",
    "            print('Loading %s generator...' % self.name)\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(gen_weights_path)\n",
    "            else:\n",
    "                data = torch.load(gen_weights_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "            self.generator.load_state_dict(data['generator'])\n",
    "            self.iteration = data['iteration']\n",
    "            \n",
    "        # load discriminator only when training\n",
    "        if self.config.MODE == 1 and os.path.exists(dis_weights_path):\n",
    "            print('Loading %s discriminator...' % self.name)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(dis_weights_path)\n",
    "            else:\n",
    "                data = torch.load(dis_weights_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "            self.discriminator.load_state_dict(data['discriminator'])\n",
    "        \n",
    "        if self.config.MODE == 1 and os.path.exists(gen_adam_path):\n",
    "            print('Loading %s Generator Adam optimizer state...' % self.name)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(gen_adam_path)\n",
    "            else:\n",
    "                data = torch.load(gen_adam_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "            self.gen_optimizer.load_state_dict(data['gen_adam_state'])\n",
    "        if self.config.MODE == 1 and os.path.exists(dis_adam_path):\n",
    "            print('Loading %s Discriminator Adam optimizer state...' % self.name)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(dis_adam_path)\n",
    "            else:\n",
    "                data = torch.load(dis_adam_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "            self.dis_optimizer.load_state_dict(data['dis_adam_state'])\n",
    "            \n",
    "    def save(self):\n",
    "        print('\\nsaving %s...\\n' % self.name)\n",
    "        torch.save({\n",
    "            'iteration': self.iteration,\n",
    "            'generator': self.generator.state_dict()\n",
    "        }, self.gen_weights_path)\n",
    "\n",
    "        torch.save({\n",
    "            'discriminator': self.discriminator.state_dict()\n",
    "        }, self.dis_weights_path)\n",
    "        \n",
    "        torch.save({\n",
    "            'gen_adam_state': self.gen_optimizer.state_dict()\n",
    "        }, self.gen_adam_path)\n",
    "            \n",
    "        torch.save({\n",
    "            'dis_adam_state': self.dis_optimizer.state_dict()\n",
    "        }, self.dis_adam_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EdgeModel(BaseModel):\n",
    "    def __init__(self, config):\n",
    "        super(EdgeModel, self).__init__('EdgeModel', config)\n",
    "\n",
    "        # generator input: [grayscale(1) + edge(1) + mask(1)]\n",
    "        # discriminator input: (grayscale(1) + edge(1))\n",
    "        generator = EdgeGenerator(use_spectral_norm=True)\n",
    "        discriminator = Discriminator(in_channels=2, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
    "        if len(config.GPU) > 1:\n",
    "            generator = nn.DataParallel(generator, device_ids=[0, 1])\n",
    "            discriminator = nn.DataParallel(discriminator, config.GPU)\n",
    "        l1_loss = nn.L1Loss()\n",
    "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
    "\n",
    "        self.add_module('generator', generator)\n",
    "        self.add_module('discriminator', discriminator)\n",
    "\n",
    "        self.add_module('l1_loss', l1_loss)\n",
    "        self.add_module('adversarial_loss', adversarial_loss)\n",
    "\n",
    "        self.gen_optimizer = optim.Adam(\n",
    "            params=generator.parameters(),\n",
    "            lr=float(config.LR),\n",
    "            betas=(config.BETA1, config.BETA2)\n",
    "        )\n",
    "\n",
    "        self.dis_optimizer = optim.Adam(\n",
    "            params=discriminator.parameters(),\n",
    "            lr=float(config.LR) * float(config.D2G_LR),\n",
    "            betas=(config.BETA1, config.BETA2)\n",
    "        )\n",
    "\n",
    "    def process(self, images, edges, masks):\n",
    "        self.iteration += 1\n",
    "\n",
    "\n",
    "        # zero optimizers\n",
    "        self.gen_optimizer.zero_grad()\n",
    "        self.dis_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # process outputs\n",
    "        outputs = self(images, edges, masks)\n",
    "        gen_loss = 0\n",
    "        dis_loss = 0\n",
    "\n",
    "\n",
    "        # discriminator loss\n",
    "        dis_input_real = torch.cat((images, edges), dim=1)\n",
    "        dis_input_fake = torch.cat((images, outputs.detach()), dim=1)\n",
    "        dis_real, dis_real_feat = self.discriminator(dis_input_real)        # in: (grayscale(1) + edge(1))\n",
    "        dis_fake, dis_fake_feat = self.discriminator(dis_input_fake)        # in: (grayscale(1) + edge(1))\n",
    "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
    "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
    "        dis_loss += (dis_real_loss.clone() + dis_fake_loss.clone()) / 2\n",
    "\n",
    "\n",
    "        # generator adversarial loss\n",
    "        gen_input_fake = torch.cat((images, outputs), dim=1)\n",
    "        gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)        # in: (grayscale(1) + edge(1))\n",
    "        gen_gan_loss = self.adversarial_loss(gen_fake, True, False)\n",
    "        gen_loss += gen_gan_loss.clone()\n",
    "\n",
    "\n",
    "        # generator feature matching loss\n",
    "        gen_fm_loss = 0\n",
    "        for i in range(len(dis_real_feat)):\n",
    "            gen_fm_loss += self.l1_loss(gen_fake_feat[i], dis_real_feat[i].detach())\n",
    "        gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n",
    "        gen_loss += gen_fm_loss\n",
    "\n",
    "\n",
    "        # create logs\n",
    "        logs = [\n",
    "            (\"l_d1\", dis_loss.item()),\n",
    "            (\"l_g1\", gen_gan_loss.item()),\n",
    "            (\"l_fm\", gen_fm_loss.item()),\n",
    "        ]\n",
    "\n",
    "        return outputs, gen_loss, dis_loss, logs\n",
    "\n",
    "    def forward(self, images, edges, masks):\n",
    "        edges_masked = (edges * (1 - masks))\n",
    "        images_masked = (images * (1 - masks)) + masks\n",
    "        inputs = torch.cat((images_masked, edges_masked), dim=1)\n",
    "        outputs = self.generator(inputs, masks)                                    # in: [grayscale(1) + edge(1) + mask(1)]\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, gen_loss=None, dis_loss=None):\n",
    "        if dis_loss is not None:\n",
    "            dis_loss.backward()\n",
    "\n",
    "        if gen_loss is not None:\n",
    "            gen_loss.backward()\n",
    "        self.gen_optimizer.step()\n",
    "        self.dis_optimizer.step()\n",
    "        \n",
    "class InpaintingModel(BaseModel):\n",
    "    def __init__(self, config):\n",
    "        super(InpaintingModel, self).__init__('InpaintingModel', config)\n",
    "\n",
    "        # generator input: [rgb(3) + edge(1)]\n",
    "        # discriminator input: [rgb(3)]\n",
    "        generator = InpaintGenerator()\n",
    "        discriminator = Discriminator(in_channels=3, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
    "        if len(config.GPU) > 1:\n",
    "            generator = nn.DataParallel(generator, config.GPU)\n",
    "            discriminator = nn.DataParallel(discriminator , config.GPU)\n",
    "\n",
    "        l1_loss = nn.L1Loss()\n",
    "        perceptual_loss = PerceptualLoss()\n",
    "        style_loss = StyleLoss()\n",
    "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
    "\n",
    "        self.add_module('generator', generator)\n",
    "        self.add_module('discriminator', discriminator)\n",
    "\n",
    "        self.add_module('l1_loss', l1_loss)\n",
    "        self.add_module('perceptual_loss', perceptual_loss)\n",
    "        self.add_module('style_loss', style_loss)\n",
    "        self.add_module('adversarial_loss', adversarial_loss)\n",
    "\n",
    "        self.gen_optimizer = optim.Adam(\n",
    "            params=generator.parameters(),\n",
    "            lr=float(config.LR),\n",
    "            betas=(config.BETA1, config.BETA2)\n",
    "        )\n",
    "\n",
    "        self.dis_optimizer = optim.Adam(\n",
    "            params=discriminator.parameters(),\n",
    "            lr=float(config.LR) * float(config.D2G_LR),\n",
    "            betas=(config.BETA1, config.BETA2)\n",
    "        )\n",
    "\n",
    "    def process(self, images, edges, masks):\n",
    "        self.iteration += 1\n",
    "\n",
    "        # zero optimizers\n",
    "        self.gen_optimizer.zero_grad()\n",
    "        self.dis_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # process outputs\n",
    "        outputs = self(images, edges, masks)\n",
    "        gen_loss = 0\n",
    "        dis_loss = 0\n",
    "\n",
    "\n",
    "        # discriminator loss\n",
    "        dis_input_real = images\n",
    "        dis_input_fake = outputs.detach()\n",
    "        dis_real, _ = self.discriminator(dis_input_real)                    # in: [rgb(3)]\n",
    "        dis_fake, _ = self.discriminator(dis_input_fake)                    # in: [rgb(3)]\n",
    "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
    "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
    "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
    "\n",
    "\n",
    "        # generator adversarial loss\n",
    "        gen_input_fake = outputs\n",
    "        gen_fake, _ = self.discriminator(gen_input_fake)                    # in: [rgb(3)]\n",
    "        gen_gan_loss = self.adversarial_loss(gen_fake, True, False) * self.config.INPAINT_ADV_LOSS_WEIGHT\n",
    "        gen_loss += gen_gan_loss\n",
    "\n",
    "\n",
    "        # generator l1 loss\n",
    "        gen_l1_loss = self.l1_loss(outputs, images) * self.config.L1_LOSS_WEIGHT / torch.mean(masks)\n",
    "        gen_loss += gen_l1_loss\n",
    "\n",
    "\n",
    "        # generator perceptual loss\n",
    "        gen_content_loss = self.perceptual_loss(outputs, images)\n",
    "        gen_content_loss = gen_content_loss * self.config.CONTENT_LOSS_WEIGHT\n",
    "        gen_loss += gen_content_loss\n",
    "\n",
    "\n",
    "        # generator style loss\n",
    "        gen_style_loss = self.style_loss(outputs * masks, images * masks)\n",
    "        gen_style_loss = gen_style_loss * self.config.STYLE_LOSS_WEIGHT\n",
    "        gen_loss += gen_style_loss\n",
    "\n",
    "\n",
    "        # create logs\n",
    "        logs = [\n",
    "            (\"l_d2\", dis_loss.item()),\n",
    "            (\"l_g2\", gen_gan_loss.item()),\n",
    "            (\"l_l1\", gen_l1_loss.item()),\n",
    "            (\"l_per\", gen_content_loss.item()),\n",
    "            (\"l_sty\", gen_style_loss.item()),\n",
    "        ]\n",
    "\n",
    "        return outputs, gen_loss, dis_loss, logs\n",
    "\n",
    "    def forward(self, images, edges, masks):\n",
    "        images_masked = (images * (1 - masks).float()) + masks\n",
    "        inputs = torch.cat((images_masked, edges), dim=1)\n",
    "        outputs = self.generator(inputs)                                    # in: [rgb(3) + edge(1)]\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, gen_loss=None, dis_loss=None):\n",
    "        dis_loss.backward()\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        self.dis_optimizer.step()\n",
    "        self.gen_optimizer.step()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.911656Z",
     "iopub.execute_input": "2023-05-18T14:34:23.912052Z",
     "iopub.status.idle": "2023-05-18T14:34:23.968314Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.912013Z",
     "shell.execute_reply": "2023-05-18T14:34:23.967192Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EdgeAccuracy(nn.Module):\n",
    "    \"\"\"\n",
    "    Measures the accuracy of the edge map\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super(EdgeAccuracy, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, inputs, outputs):\n",
    "        labels = (inputs > self.threshold)\n",
    "        outputs = (outputs > self.threshold)\n",
    "\n",
    "        relevant = torch.sum(labels.float())\n",
    "        selected = torch.sum(outputs.float())\n",
    "\n",
    "        if relevant == 0 and selected == 0:\n",
    "            return torch.tensor(1), torch.tensor(1)\n",
    "\n",
    "        true_positive = ((outputs == labels) * labels).float()\n",
    "        recall = torch.sum(true_positive) / (relevant + 1e-8)\n",
    "        precision = torch.sum(true_positive) / (selected + 1e-8)\n",
    "\n",
    "        return precision, recall\n",
    "\n",
    "\n",
    "class PSNR(nn.Module):\n",
    "    def __init__(self, max_val):\n",
    "        super(PSNR, self).__init__()\n",
    "\n",
    "        base10 = torch.log(torch.tensor(10.0))\n",
    "        max_val = torch.tensor(max_val).float()\n",
    "\n",
    "        self.register_buffer('base10', base10)\n",
    "        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n",
    "\n",
    "    def __call__(self, a, b):\n",
    "        mse = torch.mean((a.float() - b.float()) ** 2)\n",
    "\n",
    "        if mse == 0:\n",
    "            return torch.tensor(0)\n",
    "\n",
    "        return self.max_val - 10 * torch.log(mse) / self.base10"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.972388Z",
     "iopub.execute_input": "2023-05-18T14:34:23.972698Z",
     "iopub.status.idle": "2023-05-18T14:34:23.987230Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.972670Z",
     "shell.execute_reply": "2023-05-18T14:34:23.986130Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def create_mask(width, height, mask_width, mask_height, x=None, y=None):\n",
    "    mask = np.zeros((height, width))\n",
    "    mask_x = x if x is not None else random.randint(0, width - mask_width)\n",
    "    mask_y = y if y is not None else random.randint(0, height - mask_height)\n",
    "    mask[mask_y:mask_y + mask_height, mask_x:mask_x + mask_width] = 1\n",
    "    return mask\n",
    "\n",
    "def stitch_images(inputs, *outputs, img_per_row=2):\n",
    "    gap = 5\n",
    "    columns = len(outputs) + 1\n",
    "\n",
    "    width, height = inputs[0][:, :, 0].shape\n",
    "    img = Image.new('RGB', (width * img_per_row * columns + gap * (img_per_row - 1), height * int(len(inputs) / img_per_row)))\n",
    "    images = [inputs, *outputs]\n",
    "\n",
    "    for ix in range(len(inputs)):\n",
    "        xoffset = int(ix % img_per_row) * width * columns + int(ix % img_per_row) * gap\n",
    "        yoffset = int(ix / img_per_row) * height\n",
    "\n",
    "        for cat in range(len(images)):\n",
    "            im = np.array((images[cat][ix]).cpu()).astype(np.uint8).squeeze()\n",
    "            im = Image.fromarray(im)\n",
    "            img.paste(im, (xoffset + cat * width, yoffset))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def imshow(img, title=''):\n",
    "    fig = plt.gcf()\n",
    "    fig.canvas.set_window_title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, interpolation='none')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def imsave(img, path):\n",
    "    im = Image.fromarray(img.cpu().numpy().astype(np.uint8).squeeze())\n",
    "    im.save(path)\n",
    "\n",
    "class Progbar(object):\n",
    "    \"\"\"Displays a progress bar.\n",
    "    Arguments:\n",
    "        target: Total number of steps expected, None if unknown.\n",
    "        width: Progress bar width on screen.\n",
    "        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n",
    "        stateful_metrics: Iterable of string names of metrics that\n",
    "            should *not* be averaged over time. Metrics in this list\n",
    "            will be displayed as-is. All others will be averaged\n",
    "            by the progbar before display.\n",
    "        interval: Minimum visual progress update interval (in seconds).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target, width=25, verbose=1, interval=0.05,\n",
    "                 stateful_metrics=None):\n",
    "        self.target = target\n",
    "        self.width = width\n",
    "        self.verbose = verbose\n",
    "        self.interval = interval\n",
    "        if stateful_metrics:\n",
    "            self.stateful_metrics = set(stateful_metrics)\n",
    "        else:\n",
    "            self.stateful_metrics = set()\n",
    "\n",
    "        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n",
    "                                  sys.stdout.isatty()) or\n",
    "                                 'ipykernel' in sys.modules or\n",
    "                                 'posix' in sys.modules)\n",
    "        self._total_width = 0\n",
    "        self._seen_so_far = 0\n",
    "        # We use a dict + list to avoid garbage collection\n",
    "        # issues found in OrderedDict\n",
    "        self._values = {}\n",
    "        self._values_order = []\n",
    "        self._start = time.time()\n",
    "        self._last_update = 0\n",
    "\n",
    "    def update(self, current, values=None):\n",
    "        \"\"\"Updates the progress bar.\n",
    "        Arguments:\n",
    "            current: Index of current step.\n",
    "            values: List of tuples:\n",
    "                `(name, value_for_last_step)`.\n",
    "                If `name` is in `stateful_metrics`,\n",
    "                `value_for_last_step` will be displayed as-is.\n",
    "                Else, an average of the metric over time will be displayed.\n",
    "        \"\"\"\n",
    "        values = values or []\n",
    "        for k, v in values:\n",
    "            if k not in self._values_order:\n",
    "                self._values_order.append(k)\n",
    "            if k not in self.stateful_metrics:\n",
    "                if k not in self._values:\n",
    "                    self._values[k] = [v * (current - self._seen_so_far),\n",
    "                                       current - self._seen_so_far]\n",
    "                else:\n",
    "                    self._values[k][0] += v * (current - self._seen_so_far)\n",
    "                    self._values[k][1] += (current - self._seen_so_far)\n",
    "            else:\n",
    "                self._values[k] = v\n",
    "        self._seen_so_far = current\n",
    "\n",
    "        now = time.time()\n",
    "        info = ' - %.0fs' % (now - self._start)\n",
    "        if self.verbose == 1:\n",
    "            if (now - self._last_update < self.interval and\n",
    "                    self.target is not None and current < self.target):\n",
    "                return\n",
    "\n",
    "            prev_total_width = self._total_width\n",
    "            if self._dynamic_display:\n",
    "                sys.stdout.write('\\b' * prev_total_width)\n",
    "                sys.stdout.write('\\r')\n",
    "            else:\n",
    "                sys.stdout.write('\\n')\n",
    "\n",
    "            if self.target is not None:\n",
    "                numdigits = int(np.floor(np.log10(self.target))) + 1\n",
    "                barstr = '%%%dd/%d [' % (numdigits, self.target)\n",
    "                bar = barstr % current\n",
    "                prog = float(current) / self.target\n",
    "                prog_width = int(self.width * prog)\n",
    "                if prog_width > 0:\n",
    "                    bar += ('=' * (prog_width - 1))\n",
    "                    if current < self.target:\n",
    "                        bar += '>'\n",
    "                    else:\n",
    "                        bar += '='\n",
    "                bar += ('.' * (self.width - prog_width))\n",
    "                bar += ']'\n",
    "            else:\n",
    "                bar = '%7d/Unknown' % current\n",
    "\n",
    "            self._total_width = len(bar)\n",
    "#             sys.stdout.write(bar)\n",
    "            print(bar)\n",
    "\n",
    "            if current:\n",
    "                time_per_unit = (now - self._start) / current\n",
    "            else:\n",
    "                time_per_unit = 0\n",
    "            if self.target is not None and current < self.target:\n",
    "                eta = time_per_unit * (self.target - current)\n",
    "                if eta > 3600:\n",
    "                    eta_format = '%d:%02d:%02d' % (eta // 3600,\n",
    "                                                   (eta % 3600) // 60,\n",
    "                                                   eta % 60)\n",
    "                elif eta > 60:\n",
    "                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n",
    "                else:\n",
    "                    eta_format = '%ds' % eta\n",
    "\n",
    "                info = ' - ETA: %s' % eta_format\n",
    "            else:\n",
    "                if time_per_unit >= 1:\n",
    "                    info += ' %.0fs/step' % time_per_unit\n",
    "                elif time_per_unit >= 1e-3:\n",
    "                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n",
    "                else:\n",
    "                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n",
    "\n",
    "            for k in self._values_order:\n",
    "                info += ' - %s:' % k\n",
    "                if isinstance(self._values[k], list):\n",
    "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
    "                    if abs(avg) > 1e-3:\n",
    "                        info += ' %.4f' % avg\n",
    "                    else:\n",
    "                        info += ' %.4e' % avg\n",
    "                else:\n",
    "                    info += ' %s' % self._values[k]\n",
    "\n",
    "            self._total_width += len(info)\n",
    "            if prev_total_width > self._total_width:\n",
    "                info += (' ' * (prev_total_width - self._total_width))\n",
    "\n",
    "            if self.target is not None and current >= self.target:\n",
    "                info += '\\n'\n",
    "\n",
    "#             sys.stdout.write(info)\n",
    "            print(info)\n",
    "\n",
    "        elif self.verbose == 2:\n",
    "            if self.target is None or current >= self.target:\n",
    "                for k in self._values_order:\n",
    "                    info += ' - %s:' % k\n",
    "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
    "                    if avg > 1e-3:\n",
    "                        info += ' %.4f' % avg\n",
    "                    else:\n",
    "                        info += ' %.4e' % avg\n",
    "                info += '\\n'\n",
    "\n",
    "                sys.stdout.write(info)\n",
    "                print(info)\n",
    "        self._last_update = now\n",
    "\n",
    "    def add(self, n, values=None):\n",
    "        self.update(self._seen_so_far + n, values)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:23.990200Z",
     "iopub.execute_input": "2023-05-18T14:34:23.990947Z",
     "iopub.status.idle": "2023-05-18T14:34:24.033139Z",
     "shell.execute_reply.started": "2023-05-18T14:34:23.990802Z",
     "shell.execute_reply": "2023-05-18T14:34:24.032094Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import tensorflow as tf\n",
    "# from .dataset import Dataset\n",
    "# from .models import EdgeModel, InpaintingModel\n",
    "# from .utils import Progbar, create_dir, stitch_images, imsave\n",
    "# from .metrics import PSNR, EdgeAccuracy\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "class EdgeConnect():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in config.GPU)\n",
    "        if torch.cuda.is_available():\n",
    "            config.DEVICE = torch.device(\"cuda\")\n",
    "            torch.backends.cudnn.benchmark = True   # cudnn auto-tuner\n",
    "        else:\n",
    "            config.DEVICE = torch.device(\"cpu\")\n",
    "        \n",
    "        if config.MODEL == 1:\n",
    "            model_name = 'edge'\n",
    "        elif config.MODEL == 2:\n",
    "            model_name = 'inpaint'\n",
    "        elif config.MODEL == 3:\n",
    "            model_name = 'edge_inpaint'\n",
    "        elif config.MODEL == 4:\n",
    "            model_name = 'joint'\n",
    "        self.debug = True\n",
    "        self.model_name = model_name\n",
    "        self.edge_model = EdgeModel(config).to(config.DEVICE)\n",
    "#         print(summary(self.edge_model.get_submodule('generator'),(8, 2, 256, 256)))\n",
    "        self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\n",
    "        \n",
    "        self.edgeacc = EdgeAccuracy(config.EDGE_THRESHOLD).to(config.DEVICE)\n",
    "        self.psnr = PSNR(255.0).to(config.DEVICE)\n",
    "        self.train_dataset = Dataset(256, './Humans/', augment=True, training=True, isVal=False, facesDataSet=True)\n",
    "        self.val_dataset = Dataset(256, './Humans/', augment=False, training=True, isVal=True, facesDataSet=True)\n",
    "        self.sample_iterator = self.val_dataset.create_iterator(config.SAMPLE_SIZE)\n",
    "        \n",
    "        self.samples_path = os.path.join(config.PATH, 'samples')\n",
    "        self.results_path = os.path.join(config.PATH, 'results')\n",
    "        \n",
    "        self.log_file = os.path.join(config.PATH, 'log_' + model_name + '.dat')\n",
    "        \n",
    "    def train(self):\n",
    "        # Train\n",
    "        epoch = 0\n",
    "        keep_training = True\n",
    "        model = self.config.MODEL\n",
    "        max_iteration = int(float((self.config.MAX_ITERS)))\n",
    "        \n",
    "        total = len(self.train_dataset)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            num_workers=4,\n",
    "            drop_last=True,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "#         self.load()\n",
    "        while(keep_training):\n",
    "            epoch += 1\n",
    "            print('\\n\\nTraining epoch: %d' % epoch)\n",
    "\n",
    "            progbar = Progbar(total, width=20, verbose=1, stateful_metrics=['epoch', 'iter'])\n",
    "            for items in train_loader:\n",
    "\n",
    "                self.edge_model.train()\n",
    "                self.inpaint_model.train()\n",
    "                images, images_gray, edges, masks = self.cuda(*items)\n",
    "                # train\n",
    "                outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n",
    "\n",
    "                # metrics\n",
    "                precision, recall = self.edgeacc(edges * masks, outputs * masks)\n",
    "                logs.append(('precision', precision.item()))\n",
    "                logs.append(('recall', recall.item()))\n",
    "\n",
    "                # backward\n",
    "                self.edge_model.backward(gen_loss, dis_loss)\n",
    "\n",
    "                outputs, gen_loss, dis_loss, logsInpaint = self.inpaint_model.process(images, edges, masks)\n",
    "                logs += logsInpaint\n",
    "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
    "\n",
    "                # metrics\n",
    "                psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
    "                mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
    "                logs.append(('psnr', psnr.item()))\n",
    "                logs.append(('mae', mae.item()))\n",
    "\n",
    "                # backward\n",
    "                self.inpaint_model.backward(gen_loss, dis_loss)\n",
    "                iteration = self.inpaint_model.iteration\n",
    "\n",
    "                if iteration >= max_iteration:\n",
    "                    keep_training = False\n",
    "                    break\n",
    "\n",
    "                logs = [\n",
    "                    (\"epoch\", epoch),\n",
    "                    (\"iter\", iteration),\n",
    "                ] + logs\n",
    "\n",
    "                progbar.add(len(images), values=logs if self.config.VERBOSE else [x for x in logs if not x[0].startswith('l_')])\n",
    "\n",
    "                # log model at checkpoints\n",
    "                if self.config.LOG_INTERVAL and iteration % self.config.LOG_INTERVAL == 0:\n",
    "                    self.log(logs)\n",
    "\n",
    "                # sample model at checkpoints\n",
    "                if self.config.SAMPLE_INTERVAL and iteration % self.config.SAMPLE_INTERVAL == 0:\n",
    "                    self.sample()\n",
    "\n",
    "                # evaluate model at checkpoints\n",
    "#                 if self.config.EVAL_INTERVAL and iteration % self.config.EVAL_INTERVAL == 0:\n",
    "#                     print('\\nstart eval...\\n')\n",
    "#                     self.eval()\n",
    "\n",
    "                # save model at checkpoints\n",
    "                if self.config.SAVE_INTERVAL and iteration % self.config.SAVE_INTERVAL == 0:\n",
    "                    self.save()\n",
    "\n",
    "            print('\\nEnd training....')\n",
    "    \n",
    "    def cuda(self, *args):\n",
    "        return (item.to(self.config.DEVICE) for item in args)\n",
    "    \n",
    "    def load(self):\n",
    "        if self.config.MODEL == 1:\n",
    "            self.edge_model.load()\n",
    "\n",
    "        elif self.config.MODEL == 2:\n",
    "            self.inpaint_model.load()\n",
    "\n",
    "        else:\n",
    "            self.edge_model.load()\n",
    "            self.inpaint_model.load()\n",
    "\n",
    "    def save(self):\n",
    "        if self.config.MODEL == 1:\n",
    "            self.edge_model.save()\n",
    "\n",
    "        elif self.config.MODEL == 2 or self.config.MODEL == 3:\n",
    "            self.inpaint_model.save()\n",
    "\n",
    "        else:\n",
    "            self.edge_model.save()\n",
    "            self.inpaint_model.save()\n",
    "        \n",
    "    def log(self, logs):\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write('%s\\n' % ' '.join([str(item[1]) for item in logs]))\n",
    "            \n",
    "    def postprocess(self, img):\n",
    "        # [0, 1] => [0, 255]\n",
    "        img = img * 255.0\n",
    "        img = img.permute(0, 2, 3, 1)\n",
    "        return img.int()\n",
    "    \n",
    "    def eval(self):\n",
    "        val_loader = DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            drop_last=True,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        model = self.config.MODEL\n",
    "        total = len(self.val_dataset)\n",
    "\n",
    "        self.edge_model.eval()\n",
    "#         self.inpaint_model.eval()\n",
    "\n",
    "        progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
    "        iteration = 0\n",
    "\n",
    "        for items in val_loader:\n",
    "            iteration += 1\n",
    "            images, images_gray, edges, masks = self.cuda(*items)\n",
    "\n",
    "            # edge model\n",
    "            if model == 1:\n",
    "                # eval\n",
    "                outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n",
    "\n",
    "                # metrics\n",
    "                precision, recall = self.edgeacc(edges * masks, outputs * masks)\n",
    "                logs.append(('precision', precision.item()))\n",
    "                logs.append(('recall', recall.item()))\n",
    "        logs = [(\"it\", iteration), ] + logs\n",
    "        progbar.add(len(images), values=logs)\n",
    "        \n",
    "    def test(self):\n",
    "        self.edge_model.eval()\n",
    "        self.inpaint_model.eval()\n",
    "\n",
    "        model = self.config.MODEL\n",
    "        create_dir(self.results_path)\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=1,\n",
    "        )\n",
    "\n",
    "        index = 0\n",
    "        for items in test_loader:\n",
    "            name = self.test_dataset.load_name(index)\n",
    "            images, images_gray, edges, masks = self.cuda(*items)\n",
    "            index += 1\n",
    "\n",
    "            # edge model\n",
    "            if model == 1:\n",
    "                outputs = self.edge_model(images_gray, edges, masks)\n",
    "                outputs_merged = (outputs * masks) + (edges * (1 - masks))\n",
    "\n",
    "            # inpaint model\n",
    "            elif model == 2:\n",
    "                outputs = self.inpaint_model(images, edges, masks)\n",
    "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
    "\n",
    "            # inpaint with edge model / joint model\n",
    "            else:\n",
    "                print('in joint')\n",
    "                inputs = (images * (1 - masks)) + masks\n",
    "                edges = self.edge_model(images_gray, edges, masks).detach()\n",
    "                outputs = self.inpaint_model(images, edges, masks)\n",
    "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
    "\n",
    "            output = self.postprocess(outputs_merged)[0]\n",
    "            \n",
    "            images = stitch_images(\n",
    "            self.postprocess(images),\n",
    "            self.postprocess(inputs),\n",
    "            self.postprocess(edges),\n",
    "            self.postprocess(outputs_merged)\n",
    "        )\n",
    "            \n",
    "            path = os.path.join(self.results_path, name)\n",
    "            print(index, name)\n",
    "            images.save(path)\n",
    "#             imsave(output, path)\n",
    "\n",
    "#             if self.debug:\n",
    "#                 edges = self.postprocess(1 - edges)[0]\n",
    "#                 masked = self.postprocess(images * (1 - masks) + masks)[0]\n",
    "#                 fname, fext = name.split('.')\n",
    "\n",
    "#                 imsave(edges, os.path.join(self.results_path, fname + '_edge.' + fext))\n",
    "#                 imsave(masked, os.path.join(self.results_path, fname + '_masked.' + fext))\n",
    "\n",
    "        print('\\nEnd test....')     \n",
    "        \n",
    "    def sample(self, it=None):\n",
    "        # do not sample when validation set is empty\n",
    "        if len(self.val_dataset) == 0:\n",
    "            return\n",
    "\n",
    "        self.edge_model.eval()\n",
    "        self.inpaint_model.eval()\n",
    "\n",
    "        model = self.config.MODEL\n",
    "        items = next(self.sample_iterator)\n",
    "        images, images_gray, edges, masks = self.cuda(*items)\n",
    "\n",
    "        # edge model\n",
    "        if model == 1:\n",
    "            iteration = self.edge_model.iteration\n",
    "            inputs = (images_gray * (1 - masks)) + masks\n",
    "            outputs = self.edge_model(images_gray, edges, masks)\n",
    "            outputs_merged = (outputs * masks) + (edges * (1 - masks))\n",
    "\n",
    "        # inpaint model\n",
    "        elif model == 2:\n",
    "            iteration = self.inpaint_model.iteration\n",
    "            inputs = (images * (1 - masks)) + masks\n",
    "            outputs = self.inpaint_model(images, edges, masks)\n",
    "            outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
    "\n",
    "        # inpaint with edge model / joint model\n",
    "        else:\n",
    "            iteration = self.inpaint_model.iteration\n",
    "            inputs = (images * (1 - masks)) + masks\n",
    "            outputs = self.edge_model(images_gray, edges, masks).detach()\n",
    "            edges = (outputs * masks + edges * (1 - masks)).detach()\n",
    "            outputs = self.inpaint_model(images, edges, masks)\n",
    "            outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
    "\n",
    "        if it is not None:\n",
    "            iteration = it\n",
    "\n",
    "        image_per_row = 2\n",
    "        if self.config.SAMPLE_SIZE <= 6:\n",
    "            image_per_row = 1\n",
    "\n",
    "        images = stitch_images(\n",
    "            self.postprocess(images),\n",
    "            self.postprocess(inputs),\n",
    "            self.postprocess(edges),\n",
    "            self.postprocess(outputs),\n",
    "            self.postprocess(outputs_merged),\n",
    "            img_per_row = image_per_row\n",
    "        )\n",
    "\n",
    "\n",
    "        path = os.path.join(self.samples_path, self.model_name)\n",
    "        name = os.path.join(path, str(iteration).zfill(5) + \".png\")\n",
    "        create_dir(path)\n",
    "        print('\\nsaving sample ' + name)\n",
    "        images.save(name)\n",
    "\n",
    "    #             images = edges[0,...]\n",
    "    #             images = images[0,...]\n",
    "    #             print(tf.shape(images))\n",
    "    #             arr_ = np.squeeze(images) # you can give axis attribute if you wanna squeeze in specific dimension\n",
    "    #             plt.imshow(arr_, cmap=\"gray\")\n",
    "    #             plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:24.034953Z",
     "iopub.execute_input": "2023-05-18T14:34:24.035318Z",
     "iopub.status.idle": "2023-05-18T14:34:24.095446Z",
     "shell.execute_reply.started": "2023-05-18T14:34:24.035281Z",
     "shell.execute_reply": "2023-05-18T14:34:24.094387Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "config = Config()\nedgeConnect = EdgeConnect(config)\nedgeConnect.train()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T14:34:24.100399Z",
     "iopub.execute_input": "2023-05-18T14:34:24.100783Z",
     "iopub.status.idle": "2023-05-18T14:35:04.436778Z",
     "shell.execute_reply.started": "2023-05-18T14:34:24.100744Z",
     "shell.execute_reply": "2023-05-18T14:35:04.434216Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training epoch: 1\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25148\\2725360406.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mconfig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mConfig\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0medgeConnect\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEdgeConnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0medgeConnect\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25148\\3891908699.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[0mprogbar\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mProgbar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtotal\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwidth\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstateful_metrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'epoch'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'iter'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mitems\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0medge_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 435\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    436\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    437\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_worker_number_rationality\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 381\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1032\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1033\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1034\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1035\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1036\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\moshpe\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ]
  }
 ]
}